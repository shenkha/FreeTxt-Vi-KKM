{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully loaded teencode map from ./teencode.txt\n",
      "Successfully loaded stopwords list from /data/elo/khanglg/FreeTxt-Flask/vietnamese-stopwords.txt\n",
      "Using device: cuda:1\n",
      "Successfully loaded 1942 Vietnamese stopwords from vietnamese-stopwords.txt.\n",
      "Loading dataset from: sentiment_analysis_dataset.csv\n",
      "Deterministically selected the 20% validation split (9523 samples out of 47611) consistent with training procedure (using SEED: 42).\n",
      "Using 9523 rows for evaluation, corresponding to the validation set.\n",
      "Loaded 9523 samples for evaluation after cleaning and sampling.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from transformers import (\n",
    "    AutoTokenizer,\n",
    "    AutoModelForSequenceClassification,\n",
    ")\n",
    "from torch.utils.data import DataLoader, TensorDataset, SequentialSampler\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "import re\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import unicodedata\n",
    "import string\n",
    "from underthesea import word_tokenize\n",
    "\n",
    "# Using unique names for globals in this cell to avoid conflicts\n",
    "PUNCS_CELL_EVAL = '''!→()-[]{};:'\"\\\\,<>?@#$%^&*_~'''\n",
    "vi_stopwords_global_cell_eval = set()\n",
    "device_global_cell_eval = torch.device(\"cpu\") # Will be updated\n",
    "\n",
    "# --- Helper Functions (Adapted from finetuneSA.py for evaluation in this notebook cell) ---\n",
    "\n",
    "def preprocess_text_cell_eval(text):\n",
    "    \"\"\"\n",
    "    Preprocesses text for sentiment analysis for this evaluation cell.\n",
    "    Uses global vi_stopwords_global_cell_eval and PUNCS_CELL_EVAL.\n",
    "    \"\"\"\n",
    "    global vi_stopwords_global_cell_eval, PUNCS_CELL_EVAL\n",
    "    text = str(text)\n",
    "    # Regex from finetuneSA.py: re.sub(r\"http\\\\S+|@\\\\S+|#\\\\S+\", \"\", text)\n",
    "    # In a standard Python string, \\\\S becomes \\S. This is equivalent to r\"http\\S+|@\\S+|#\\S+\"\n",
    "    text = re.sub(r\"http\\S+|@\\S+|#\\S+\", \"\", text) \n",
    "    text = re.sub(f\"[{re.escape(''.join(PUNCS_CELL_EVAL))}]\", \"\", text.lower())\n",
    "    text = \" \".join(word for word in text.split() if word not in vi_stopwords_global_cell_eval)\n",
    "    return text\n",
    "\n",
    "# It's recommended to add these imports to the top of your notebook cell if not already present:\n",
    "# import string\n",
    "# import unicodedata\n",
    "# from underthesea import word_tokenize\n",
    "# pandas (pd) and re are already imported in the cell.\n",
    "\n",
    "# --- Data structures and helper functions from Vi_preprocessing.ipynb (adapted for this cell) ---\n",
    "# These are prefixed with _v2 or defined locally to avoid conflicts if similar names exist globally.\n",
    "\n",
    "bang_nguyen_am_v2 = [['a', 'à', 'á', 'ả', 'ã', 'ạ', 'a'],\n",
    "                  ['ă', 'ằ', 'ắ', 'ẳ', 'ẵ', 'ặ', 'aw'],\n",
    "                  ['â', 'ầ', 'ấ', 'ẩ', 'ẫ', 'ậ', 'aa'],\n",
    "                  ['e', 'è', 'é', 'ẻ', 'ẽ', 'ẹ', 'e'],\n",
    "                  ['ê', 'ề', 'ế', 'ể', 'ễ', 'ệ', 'ee'],\n",
    "                  ['i', 'ì', 'í', 'ỉ', 'ĩ', 'ị', 'i'],\n",
    "                  ['o', 'ò', 'ó', 'ỏ', 'õ', 'ọ', 'o'],\n",
    "                  ['ô', 'ồ', 'ố', 'ổ', 'ỗ', 'ộ', 'oo'],\n",
    "                  ['ơ', 'ờ', 'ớ', 'ở', 'ỡ', 'ợ', 'ow'],\n",
    "                  ['u', 'ù', 'ú', 'ủ', 'ũ', 'ụ', 'u'],\n",
    "                  ['ư', 'ừ', 'ứ', 'ử', 'ữ', 'ự', 'uw'],\n",
    "                  ['y', 'ỳ', 'ý', 'ỷ', 'ỹ', 'ỵ', 'y']]\n",
    "bang_ky_tu_dau_v2 = ['', 'f', 's', 'r', 'x', 'j']\n",
    "\n",
    "nguyen_am_to_ids_v2 = {}\n",
    "for i in range(len(bang_nguyen_am_v2)):\n",
    "    for j in range(len(bang_nguyen_am_v2[i]) - 1):\n",
    "        nguyen_am_to_ids_v2[bang_nguyen_am_v2[i][j]] = (i, j)\n",
    "\n",
    "def loaddicchar_v2():\n",
    "    dic = {}\n",
    "    char1252 = 'à|á|ả|ã|ạ|ầ|ấ|ẩ|ẫ|ậ|ằ|ắ|ẳ|ẵ|ặ|è|é|ẻ|ẽ|ẹ|ề|ế|ể|ễ|ệ|ì|í|ỉ|ĩ|ị|ò|ó|ỏ|õ|ọ|ồ|ố|ổ|ỗ|ộ|ờ|ớ|ở|ỡ|ợ|ù|ú|ủ|ũ|ụ|ừ|ứ|ử|ữ|ự|ỳ|ý|ỷ|ỹ|ỵ|À|Á|Ả|Ã|Ạ|Ầ|Ấ|Ẩ|Ẫ|Ậ|Ằ|Ắ|Ẳ|Ẵ|Ặ|È|É|Ẻ|Ẽ|Ẹ|Ề|Ế|Ể|Ễ|Ệ|Ì|Í|Ỉ|Ĩ|Ị|Ò|Ó|Ỏ|Õ|Ọ|Ồ|Ố|Ổ|Ỗ|Ộ|Ờ|Ớ|Ở|Ỡ|Ợ|Ù|Ú|Ủ|Ũ|Ụ|Ừ|Ứ|Ử|Ữ|Ự|Ỳ|Ý|Ỷ|Ỹ|Ỵ'.split('|')\n",
    "    charutf8 = \"à|á|ả|ã|ạ|ầ|ấ|ẩ|ẫ|ậ|ằ|ắ|ẳ|ẵ|ặ|è|é|ẻ|ẽ|ẹ|ề|ế|ể|ễ|ệ|ì|í|ỉ|ĩ|ị|ò|ó|ỏ|õ|ọ|ồ|ố|ổ|ỗ|ộ|ờ|ớ|ở|ỡ|ợ|ù|ú|ủ|ũ|ụ|ừ|ứ|ử|ữ|ự|ỳ|ý|ỷ|ỹ|ỵ|À|Á|Ả|Ã|Ạ|Ầ|Ấ|Ẩ|Ẫ|Ậ|Ằ|Ắ|Ẳ|Ẵ|Ặ|È|É|Ẻ|Ẽ|Ẹ|Ề|Ế|Ể|Ễ|Ệ|Ì|Í|Ỉ|Ĩ|Ị|Ò|Ó|Ỏ|Õ|Ọ|Ồ|Ố|Ổ|Ỗ|Ộ|Ờ|Ớ|Ở|Ỡ|Ợ|Ù|Ú|Ủ|Ũ|Ụ|Ừ|Ứ|Ử|Ữ|Ự|Ỳ|Ý|Ỷ|Ỹ|Ỵ\".split('|')\n",
    "    for i in range(len(char1252)):\n",
    "        dic[char1252[i]] = charutf8[i]\n",
    "    return dic\n",
    "dicchar_v2 = loaddicchar_v2()\n",
    "\n",
    "# --- Load Teencode Data ---\n",
    "_teencode_file_path_v2 = './teencode.txt' \n",
    "try:\n",
    "    teencode_df_v2 = pd.read_csv(_teencode_file_path_v2, names=['teencode', 'map'], sep='\\t', header=None)\n",
    "    teencode_map_default_v2 = pd.Series(teencode_df_v2['map'].values, index=teencode_df_v2['teencode']).to_dict()\n",
    "    print(f\"Successfully loaded teencode map from {_teencode_file_path_v2}\")\n",
    "except FileNotFoundError:\n",
    "    print(f\"Warning: Teencode file not found at {_teencode_file_path_v2}. Teencode replacement will be limited for preprocess_text_cell_eval_v2.\")\n",
    "    teencode_map_default_v2 = {}\n",
    "except Exception as e:\n",
    "    print(f\"Warning: Error loading teencode file '{_teencode_file_path_v2}': {e}. Teencode replacement will be limited for preprocess_text_cell_eval_v2.\")\n",
    "    teencode_map_default_v2 = {}\n",
    "\n",
    "# --- Load Stopwords Data ---\n",
    "_stopwords_file_path_v2 = '/data/elo/khanglg/FreeTxt-Flask/vietnamese-stopwords.txt'\n",
    "try:\n",
    "    with open(_stopwords_file_path_v2, 'r', encoding='utf-8') as f:\n",
    "        stopwords_list_default_v2 = [line.strip() for line in f if line.strip()]\n",
    "    print(f\"Successfully loaded stopwords list from {_stopwords_file_path_v2}\")\n",
    "except FileNotFoundError:\n",
    "    print(f\"Warning: Stopwords file not found at {_stopwords_file_path_v2}. Stopword removal will be limited for preprocess_text_cell_eval_v2.\")\n",
    "    stopwords_list_default_v2 = []\n",
    "except Exception as e:\n",
    "    print(f\"Warning: Error loading stopwords file '{_stopwords_file_path_v2}': {e}. Stopword removal will be limited for preprocess_text_cell_eval_v2.\")\n",
    "    stopwords_list_default_v2 = []\n",
    "\n",
    "emoji_pattern_v2 = re.compile(\"[\"\n",
    "    u\"\\U0001F600-\\U0001F64F\"  # Emoticons\n",
    "    u\"\\U0001F300-\\U0001F5FF\"  # Symbols & pictographs\n",
    "    u\"\\U0001F680-\\U0001F6FF\"  # Transport & map symbols\n",
    "    u\"\\U0001F1E0-\\U0001F1FF\"  # Flags\n",
    "    u\"\\U00002702-\\U000027B0\"\n",
    "    u\"\\U000024C2-\\U0001F251\"\n",
    "    u\"\\U0001f926-\\U0001f937\"\n",
    "    u\"\\U00010000-\\U0010ffff\"\n",
    "    u\"\\u200d\"\n",
    "    u\"\\u2640-\\u2642\"\n",
    "    u\"\\u2600-\\u2B55\"\n",
    "    u\"\\u23cf\"\n",
    "    u\"\\u23e9\"\n",
    "    u\"\\u231a\"\n",
    "    u\"\\u3030\"\n",
    "    u\"\\ufe0f\"\n",
    "    \"]+\", flags=re.UNICODE)\n",
    "\n",
    "def convert_unicode_legacy_v2(txt):\n",
    "    return re.sub(\n",
    "        r'à|á|ả|ã|ạ|ầ|ấ|ẩ|ẫ|ậ|ằ|ắ|ẳ|ẵ|ặ|è|é|ẻ|ẽ|ẹ|ề|ế|ể|ễ|ệ|ì|í|ỉ|ĩ|ị|ò|ó|ỏ|õ|ọ|ồ|ố|ổ|ỗ|ộ|ờ|ớ|ở|ỡ|ợ|ù|ú|ủ|ũ|ụ|ừ|ứ|ử|ữ|ự|ỳ|ý|ỷ|ỹ|ỵ|À|Á|Ả|Ã|Ạ|Ầ|Ấ|Ẩ|Ẫ|Ậ|Ằ|Ắ|Ẳ|Ẵ|Ặ|È|É|Ẻ|Ẽ|Ẹ|Ề|Ế|Ể|Ễ|Ệ|Ì|Í|Ỉ|Ĩ|Ị|Ò|Ó|Ỏ|Õ|Ọ|Ồ|Ố|Ổ|Ỗ|Ộ|Ờ|Ớ|Ở|Ỡ|Ợ|Ù|Ú|Ủ|Ũ|Ụ|Ừ|Ứ|Ử|Ữ|Ự|Ỳ|Ý|Ỷ|Ỹ|Ỵ',\n",
    "        lambda x: dicchar_v2[x.group()], txt)\n",
    "\n",
    "def text_unicode_normalize_v2(text):\n",
    "    # Requires: import unicodedata\n",
    "    try:\n",
    "        return unicodedata.normalize('NFC', text)\n",
    "    except NameError:\n",
    "        print(\"Warning: unicodedata module not imported. Unicode normalization (NFC) skipped.\")\n",
    "        return text\n",
    "\n",
    "# def convert_unicode_legacy(txt): # Renamed to avoid clash if user defines convert_unicode\n",
    "#     return re.sub(\n",
    "#         r'à|á|ả|ã|ạ|ầ|ấ|ẩ|ẫ|ậ|ằ|ắ|ẳ|ẵ|ặ|è|é|ẻ|ẽ|ẹ|ề|ế|ể|ễ|ệ|ì|í|ỉ|ĩ|ị|ò|ó|ỏ|õ|ọ|ồ|ố|ổ|ỗ|ộ|ờ|ớ|ở|ỡ|ợ|ù|ú|ủ|ũ|ụ|ừ|ứ|ử|ữ|ự|ỳ|ý|ỷ|ỹ|ỵ|À|Á|Ả|Ã|Ạ|Ầ|Ấ|Ẩ|Ẫ|Ậ|Ằ|Ắ|Ẳ|Ẵ|Ặ|È|É|Ẻ|Ẽ|Ẹ|Ề|Ế|Ể|Ễ|Ệ|Ì|Í|Ỉ|Ĩ|Ị|Ò|Ó|Ỏ|Õ|Ọ|Ồ|Ố|Ổ|Ỗ|Ộ|Ờ|Ớ|Ở|Ỡ|Ợ|Ù|Ú|Ủ|Ũ|Ụ|Ừ|Ứ|Ử|Ữ|Ự|Ỳ|Ý|Ỷ|Ỹ|Ỵ',\n",
    "#         lambda x: dicchar[x.group()], txt)\n",
    "\n",
    "# def text_unicode_normalize(text): # From user's snippet\n",
    "#     return unicodedata.normalize('NFC', text)\n",
    "\n",
    "\n",
    "def is_valid_vietnam_word_v2(word):\n",
    "    chars = list(word)\n",
    "    nguyen_am_index = -1\n",
    "    for index, char in enumerate(chars):\n",
    "        x, y = nguyen_am_to_ids_v2.get(char, (-1, -1))\n",
    "        if x != -1:\n",
    "            if nguyen_am_index == -1:\n",
    "                nguyen_am_index = index\n",
    "            else:\n",
    "                if index - nguyen_am_index != 1:\n",
    "                    return False\n",
    "                nguyen_am_index = index\n",
    "    return True\n",
    "\n",
    "def chuan_hoa_dau_tu_tieng_viet_v2(word):\n",
    "    if not is_valid_vietnam_word_v2(word):\n",
    "        return word\n",
    "    chars = list(word)\n",
    "    dau_cau = 0\n",
    "    nguyen_am_index = []\n",
    "    qu_or_gi = False\n",
    "    for index, char in enumerate(chars):\n",
    "        x, y = nguyen_am_to_ids_v2.get(char, (-1, -1))\n",
    "        if x == -1: continue\n",
    "        if x == 9: # u\n",
    "            if index > 0 and chars[index - 1].lower() == 'q':\n",
    "                chars[index] = 'u'; qu_or_gi = True\n",
    "        elif x == 5: # i\n",
    "            if index > 0 and chars[index - 1].lower() == 'g':\n",
    "                chars[index] = 'i'; qu_or_gi = True\n",
    "        if y != 0:\n",
    "            dau_cau = y; chars[index] = bang_nguyen_am_v2[x][0]\n",
    "        if not qu_or_gi or index != 1:\n",
    "            nguyen_am_index.append(index)\n",
    "\n",
    "    if not nguyen_am_index: return \"\".join(chars)\n",
    "\n",
    "    idx_to_mark = nguyen_am_index[0]\n",
    "    if len(nguyen_am_index) >= 2:\n",
    "        priority_vowel_found = False\n",
    "        for idx_candidate in nguyen_am_index:\n",
    "            x_vowel, _ = nguyen_am_to_ids_v2.get(chars[idx_candidate], (-1,-1))\n",
    "            if x_vowel in [4, 7, 8]: # ê, ô, ơ\n",
    "                idx_to_mark = idx_candidate\n",
    "                priority_vowel_found = True\n",
    "                break\n",
    "        \n",
    "        if not priority_vowel_found:\n",
    "            if nguyen_am_index[-1] == len(chars) -1:\n",
    "                x_last_vowel, _ = nguyen_am_to_ids_v2.get(chars[nguyen_am_index[-1]], (-1,-1))\n",
    "                if x_last_vowel in [5, 9, 10, 11]: # i, u, ư, y\n",
    "                     idx_to_mark = nguyen_am_index[-2] if len(nguyen_am_index) > 1 else nguyen_am_index[-1]\n",
    "                else: \n",
    "                    idx_to_mark = nguyen_am_index[0]\n",
    "            else: \n",
    "                if len(nguyen_am_index) == 3: \n",
    "                    idx_to_mark = nguyen_am_index[1]\n",
    "                elif len(nguyen_am_index) == 2: \n",
    "                    idx_to_mark = nguyen_am_index[1]\n",
    "\n",
    "    x_target_vowel, _ = nguyen_am_to_ids_v2.get(chars[idx_to_mark], (-1,-1))\n",
    "    if x_target_vowel != -1 and dau_cau != 0:\n",
    "        chars[idx_to_mark] = bang_nguyen_am_v2[x_target_vowel][dau_cau]\n",
    "    return \"\".join(chars)\n",
    "\n",
    "def chuan_hoa_dau_cau_tieng_viet_v2(sentence):\n",
    "    words = sentence.split()\n",
    "    for index, word in enumerate(words):\n",
    "        match = re.match(r'(^[\\W_]*)([\\wÀ-Ỹà-ỹ._]*[\\wÀ-Ỹà-ỹ]+)([\\W_]*$)', word)\n",
    "        if match:\n",
    "            prefix, core_word, suffix = match.groups()\n",
    "            normalized_core_word = chuan_hoa_dau_tu_tieng_viet_v2(core_word)\n",
    "            words[index] = prefix + normalized_core_word + suffix\n",
    "        else:\n",
    "            words[index] = chuan_hoa_dau_tu_tieng_viet_v2(word) \n",
    "    return \" \".join(words)\n",
    "\n",
    "# --- Main Preprocessing Function V2 (Adapted from Vi_preprocessing.ipynb) ---\n",
    "def preprocess_text_cell_eval_v2(\n",
    "    text,\n",
    "    custom_teencode_map=None,\n",
    "    custom_stopwords_list=None,\n",
    "    use_teencode=True,\n",
    "    use_stopwords=False,\n",
    "    remove_all_punctuation=False\n",
    "    ):\n",
    "    \"\"\"\n",
    "    Comprehensive Vietnamese text preprocessing using underthesea, adapted for notebook evaluation.\n",
    "    Requires `string`, `unicodedata`, `underthesea` modules to be imported.\n",
    "    \"\"\"\n",
    "    if not isinstance(text, str):\n",
    "        text = str(text)\n",
    "\n",
    "    current_teencode_map = custom_teencode_map if custom_teencode_map is not None else teencode_map_default_v2\n",
    "    current_stopwords_list = custom_stopwords_list if custom_stopwords_list is not None else stopwords_list_default_v2\n",
    "\n",
    "    # 1. Lowercase\n",
    "    processed_text = text.lower()\n",
    "\n",
    "    # 2. Remove URLs, mentions, hashtags\n",
    "    processed_text = re.sub(r\"http\\S+|www\\S+|@\\S+|#\\S+\", \"\", processed_text)\n",
    "\n",
    "    # 3. Legacy Unicode conversion\n",
    "    processed_text = convert_unicode_legacy_v2(processed_text)\n",
    "\n",
    "    # 4. Standard Unicode Normalization (NFC)\n",
    "    processed_text = text_unicode_normalize_v2(processed_text)\n",
    "\n",
    "    # 5. Remove Emojis\n",
    "    processed_text = re.sub(emoji_pattern_v2, \" \", processed_text)\n",
    "\n",
    "    # 6. Reduce repeated alphabetic characters\n",
    "    processed_text = re.sub(r'([a-zàáạảãâầấậẩẫăằắặẳẵèéẹẻẽêềếệểễìíịỉĩòóọỏõôồốộổỗơờớợởỡùúụủũưừứựửữỳýỵỷỹđ])\\1+', r'\\1', processed_text)\n",
    "\n",
    "    # 7. Reduce repeated special characters\n",
    "    processed_text = re.sub(r'([^a-z0-9àáạảãâầấậẩẫăằắặẳẵèéẹẻẽêềếệểễìíịỉĩòóọỏõôồốộổỗơờớợởỡùúụủũưừứựửữỳýỵỷỹđ\\s])\\1+', r'\\1', processed_text)\n",
    "    \n",
    "    try:\n",
    "        # Requires: import string\n",
    "        _local_string_punctuation = string.punctuation\n",
    "        _local_string_whitespace = string.whitespace\n",
    "    except NameError:\n",
    "        print(\"Warning: string module not imported. Using a basic punctuation set for steps 8, 9, 11, 13.\")\n",
    "        # Fallback punctuation similar to PUNCS_CELL_EVAL or finetuneSA.py's _punctuation_chars\n",
    "        _local_string_punctuation = '!\"#$%&\\'()*+,-./:;<=>?@[\\\\]^_`{|}~'\n",
    "        _local_string_whitespace = \" \\t\\n\\r\\f\\v\"\n",
    "\n",
    "\n",
    "    # 8. Normalize punctuation spacing\n",
    "    escaped_punctuation = re.escape(_local_string_punctuation)\n",
    "    processed_text = re.sub(r\"(\\w)\\s*([\" + escaped_punctuation + r\"])\\s*(\\w)\", r\"\\1 \\2 \\3\", processed_text)\n",
    "    processed_text = re.sub(r\"(\\w)\\s*([\" + escaped_punctuation + r\"])\", r\"\\1 \\2\", processed_text)\n",
    "    processed_text = re.sub(r\"([\" + escaped_punctuation + r\"])\\s*(\\w)\", r\"\\1 \\2\", processed_text)\n",
    "\n",
    "    # 9. Reduce repeated punctuation characters\n",
    "    processed_text = re.sub(r\"([\" + escaped_punctuation + r\"])\\1+\", r\"\\1\", processed_text)\n",
    "\n",
    "    # 10. Vietnamese tone mark normalization\n",
    "    processed_text = chuan_hoa_dau_cau_tieng_viet_v2(processed_text)\n",
    "\n",
    "    # 11. Remove all punctuation (optional)\n",
    "    if remove_all_punctuation:\n",
    "        translator = str.maketrans('', '', _local_string_punctuation)\n",
    "        processed_text = processed_text.translate(translator)\n",
    "\n",
    "    # 12. Final whitespace cleanup\n",
    "    processed_text = re.sub(r'\\s+', ' ', processed_text).strip()\n",
    "    \n",
    "    # 13. Strip leading/trailing punctuation or space robustly\n",
    "    if not remove_all_punctuation and processed_text:\n",
    "        strip_chars = _local_string_punctuation + _local_string_whitespace\n",
    "        while processed_text and processed_text[-1] in strip_chars:\n",
    "            processed_text = processed_text[:-1]\n",
    "        while processed_text and processed_text[0] in strip_chars:\n",
    "            processed_text = processed_text[1:]\n",
    "    \n",
    "    if not processed_text:\n",
    "        return \"\"\n",
    "\n",
    "    # 14. Tokenization using underthesea\n",
    "    try:\n",
    "        # Requires: from underthesea import word_tokenize\n",
    "        tokens = word_tokenize(processed_text, format=\"list\") \n",
    "    except NameError:\n",
    "        print(\"Warning: underthesea.word_tokenize not imported. Falling back to simple whitespace split for tokenization.\")\n",
    "        tokens = processed_text.split()\n",
    "\n",
    "\n",
    "    # 15. Teencode Replacement (on tokens)\n",
    "    if use_teencode and current_teencode_map:\n",
    "        new_tokens = []\n",
    "        for token in tokens:\n",
    "            replacement = current_teencode_map.get(token, token)\n",
    "            new_tokens.append(replacement)\n",
    "        \n",
    "        if any(\" \" in t for t in new_tokens):\n",
    "            temp_token_string = \" \".join(new_tokens)\n",
    "            try:\n",
    "                # Requires: from underthesea import word_tokenize\n",
    "                tokens = word_tokenize(temp_token_string, format=\"list\")\n",
    "            except NameError:\n",
    "                # Fallback if word_tokenize is not available after teencode\n",
    "                tokens = temp_token_string.split()\n",
    "\n",
    "        else:\n",
    "            tokens = new_tokens\n",
    "\n",
    "    # 16. Stopword Removal (on tokens)\n",
    "    if use_stopwords and current_stopwords_list:\n",
    "        tokens = [token for token in tokens if token not in current_stopwords_list and token.strip()]\n",
    "\n",
    "    # 17. Join tokens to form the final processed string\n",
    "    return \" \".join(tokens)\n",
    "\n",
    "# Example usage (optional, for testing in the notebook):\n",
    "# test_text_v2 = \"Chàoooo bạn, hôm nay trời đẹp quá!!! :))) #sunnyday @friend http://example.com\"\n",
    "# processed_v2 = preprocess_text_cell_eval_v2(test_text_v2, use_stopwords=True, use_teencode=True)\n",
    "# print(f\"Original: {test_text_v2}\")\n",
    "# print(f\"Processed V2: {processed_v2}\")\n",
    "\n",
    "# test_text_v2_punctuation = \"công ty abc .,. xin chào ! ! !\"\n",
    "# processed_v2_punc = preprocess_text_cell_eval_v2(test_text_v2_punctuation, remove_all_punctuation=True)\n",
    "# print(f\"Original: {test_text_v2_punctuation}\")\n",
    "# print(f\"Processed V2 (remove all punc): {processed_v2_punc}\")\n",
    "\n",
    "# processed_v2_punc_keep = preprocess_text_cell_eval_v2(test_text_v2_punctuation, remove_all_punctuation=False)\n",
    "# print(f\"Original: {test_text_v2_punctuation}\")\n",
    "# print(f\"Processed V2 (keep punc): {processed_v2_punc_keep}\")\n",
    "\n",
    "\n",
    "def load_model_cell_eval(model_path, num_labels):\n",
    "    \"\"\"\n",
    "    Loads a fine-tuned model and tokenizer for evaluation in this cell.\n",
    "    Uses global device_global_cell_eval.\n",
    "    Assumes model was saved using `save_pretrained` and is loadable\n",
    "    via `AutoModelForSequenceClassification.from_pretrained`.\n",
    "    \"\"\"\n",
    "    global device_global_cell_eval\n",
    "    try:\n",
    "        print(f\"Loading tokenizer from: {model_path}\")\n",
    "        tokenizer = AutoTokenizer.from_pretrained(model_path)\n",
    "        print(f\"Loading model from: {model_path}\")\n",
    "        model = AutoModelForSequenceClassification.from_pretrained(model_path, num_labels=num_labels)\n",
    "        model.to(device_global_cell_eval)\n",
    "        return tokenizer, model\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading model {model_path} using AutoModelForSequenceClassification.from_pretrained: {e}\")\n",
    "        print(\"Please ensure the model was saved correctly using `save_pretrained` and is compatible.\")\n",
    "        return None, None\n",
    "\n",
    "def prepare_data_for_cell_eval(texts, labels, tokenizer, max_length, batch_size, seed_for_split):\n",
    "    \"\"\"\n",
    "    Converts texts and labels into a PyTorch DataLoader for the validation split.\n",
    "    Uses preprocess_text_cell_eval.\n",
    "    Splits data 80/20 for train/validation using the provided seed to ensure consistency.\n",
    "    \"\"\"\n",
    "    print(\"Preprocessing texts for dataloaders...\")\n",
    "    #preprocessed_texts = [preprocess_text_cell_eval(text) for text in tqdm(texts, desc=\"Preprocessing\")]\n",
    "    preprocessed_texts = [preprocess_text_cell_eval_v2(text) for text in tqdm(texts, desc=\"Preprocessing V2\")]\n",
    "\n",
    "    \n",
    "    print(\"Tokenizing texts...\")\n",
    "    encodings = tokenizer(\n",
    "        preprocessed_texts,\n",
    "        add_special_tokens=True,\n",
    "        max_length=max_length,\n",
    "        padding='max_length',\n",
    "        truncation=True,\n",
    "        return_tensors='pt'\n",
    "    )\n",
    "    \n",
    "    dataset = TensorDataset(\n",
    "        encodings['input_ids'],\n",
    "        encodings['attention_mask'],\n",
    "        torch.tensor(labels, dtype=torch.long)\n",
    "    )\n",
    "    \n",
    "    train_size = int(0.8 * len(dataset))\n",
    "    val_size = len(dataset) - train_size\n",
    "    \n",
    "    if val_size == 0 and train_size > 0 : # Ensure val_size is at least 1 if dataset is very small\n",
    "        if train_size > 1:\n",
    "            train_size -=1\n",
    "            val_size +=1\n",
    "        else: # Cannot split if only 1 sample\n",
    "            print(\"Warning: Dataset too small to create a validation split. Using entire dataset for validation.\")\n",
    "            val_dataset = dataset\n",
    "    elif val_size == 0 and train_size == 0:\n",
    "        print(\"Error: Dataset is empty after processing.\")\n",
    "        return None\n",
    "    else:\n",
    "         # Ensure reproducibility of split using the provided seed\n",
    "        train_dataset, val_dataset = torch.utils.data.random_split(\n",
    "            dataset, \n",
    "            [train_size, val_size],\n",
    "            generator=torch.Generator().manual_seed(seed_for_split)\n",
    "        )\n",
    "    \n",
    "    print(f\"Using validation split for evaluation. Validation dataset size: {len(val_dataset)}\")\n",
    "\n",
    "    val_dataloader = DataLoader(\n",
    "        val_dataset,\n",
    "        sampler=SequentialSampler(val_dataset),\n",
    "        batch_size=batch_size\n",
    "    )\n",
    "    \n",
    "    return val_dataloader\n",
    "\n",
    "def evaluate_model_cell_eval(model, dataloader):\n",
    "    \"\"\"\n",
    "    Evaluates the model and returns accuracy and classification report.\n",
    "    Uses global device_global_cell_eval.\n",
    "    \"\"\"\n",
    "    global device_global_cell_eval\n",
    "    model.eval()\n",
    "    predictions_list = []\n",
    "    true_labels_list = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(dataloader, desc=\"Evaluating\"):\n",
    "            batch_input_ids = batch[0].to(device_global_cell_eval)\n",
    "            batch_attention_mask = batch[1].to(device_global_cell_eval)\n",
    "            batch_labels = batch[2].to(device_global_cell_eval)\n",
    "\n",
    "            outputs = model(input_ids=batch_input_ids, attention_mask=batch_attention_mask)\n",
    "            logits = outputs.logits \n",
    "            \n",
    "            preds = torch.argmax(logits, dim=1).cpu().numpy()\n",
    "            labels_np = batch_labels.cpu().numpy()\n",
    "            \n",
    "            predictions_list.extend(preds)\n",
    "            true_labels_list.extend(labels_np)\n",
    "            \n",
    "    if not true_labels_list: # Handle empty dataloader or no predictions\n",
    "        print(\"Warning: No predictions made, possibly due to an empty dataloader.\")\n",
    "        return 0.0, \"No predictions to report.\"\n",
    "\n",
    "    accuracy = accuracy_score(true_labels_list, predictions_list)\n",
    "    try:\n",
    "        unique_labels_in_data = sorted(list(set(true_labels_list)))\n",
    "        \n",
    "        # Determine target names based on unique labels present in the data and model config\n",
    "        if model.config.num_labels == 3 and all(l in [0,1,2] for l in unique_labels_in_data) :\n",
    "             # Standard 3-class sentiment\n",
    "            target_names_map = {0: 'Tiêu cực', 1: 'Trung tính', 2: 'Tích cực'}\n",
    "            current_target_names = [target_names_map[l] for l in unique_labels_in_data if l in target_names_map]\n",
    "            # If not all labels [0,1,2] are in unique_labels_in_data, classification_report might still need full list\n",
    "            # For safety, provide all expected names if num_labels is 3.\n",
    "            if len(current_target_names) < 3 and len(unique_labels_in_data) <3 : # If only a subset of labels appeared\n",
    "                 report_target_names = ['Tiêu cực', 'Trung tính', 'Tích cực'] # Full list for report\n",
    "            else:\n",
    "                 report_target_names = current_target_names\n",
    "\n",
    "        else: # Generic case\n",
    "            report_target_names = [f\"class_{i}\" for i in unique_labels_in_data]\n",
    "            if not report_target_names : # Fallback if unique_labels_in_data is empty (should not happen if true_labels_list is not empty)\n",
    "                 report_target_names = [f\"class_{i}\" for i in range(model.config.num_labels)]\n",
    "\n",
    "\n",
    "        report = classification_report(true_labels_list, predictions_list, labels=unique_labels_in_data, target_names=report_target_names, zero_division=0)\n",
    "    except ValueError as e: \n",
    "        print(f\"Warning generating classification report: {e}. Using default report (no target names).\")\n",
    "        report = classification_report(true_labels_list, predictions_list, zero_division=0)\n",
    "\n",
    "    return accuracy, report\n",
    "\n",
    "# --- Configuration for Evaluation ---\n",
    "DATASET_PATH_EVAL = \"sentiment_analysis_dataset.csv\"\n",
    "STOPWORDS_PATH_EVAL = \"vietnamese-stopwords.txt\"\n",
    "OUTPUT_DIR_BASE_EVAL = \"./fine_tuned_sa_manual_models\"\n",
    "# MODEL_IDENTIFIERS_EVAL = [\"./fine_tuned_sa_manual_models/vietnamese-bi-encoder\", \n",
    "#                           \"./fine_tuned_sa_manual_models/visobert\", \n",
    "#                           \"./fine_tuned_sa_manual_models/phobert-base-v2\",\n",
    "#                           \"./fine_tuned_sa_manual_models/Multilingual-MiniLM-L12-H384\"]\n",
    "MODEL_IDENTIFIERS_EVAL = [\"./fine_tuned_sa_manual_newPreprocess_models/vietnamese-bi-encoder\", \n",
    "                          \"./fine_tuned_sa_manual_newPreprocess_models/visobert\", \n",
    "                          ]\n",
    "\n",
    "NUM_LABELS_EVAL = 3\n",
    "MAX_SEQ_LENGTH_EVAL = 128\n",
    "BATCH_SIZE_EVAL = 24 \n",
    "# Check if cuda:7 is available, otherwise fallback\n",
    "if torch.cuda.is_available():\n",
    "    try:\n",
    "        if torch.cuda.device_count() > 1: # Check if device 7 exists\n",
    "             torch.cuda.set_device(1) # Try to set to check\n",
    "             DEVICE_STR_EVAL = \"cuda:1\"\n",
    "        else: # cuda:7 not available, use cuda:0 or other available\n",
    "             DEVICE_STR_EVAL = \"cuda\" \n",
    "    except RuntimeError: # If cuda:7 cannot be set\n",
    "        DEVICE_STR_EVAL = \"cuda\" # Fallback to default cuda\n",
    "else:\n",
    "    DEVICE_STR_EVAL = \"cpu\"\n",
    "\n",
    "SEED_EVAL = 42 # Consistent with finetuneSA.py for data splitting\n",
    "\n",
    "# --- Setup ---\n",
    "device_global_cell_eval = torch.device(DEVICE_STR_EVAL)\n",
    "torch.manual_seed(SEED_EVAL)\n",
    "np.random.seed(SEED_EVAL)\n",
    "if DEVICE_STR_EVAL.startswith(\"cuda\"):\n",
    "    torch.cuda.manual_seed_all(SEED_EVAL)\n",
    "\n",
    "print(f\"Using device: {device_global_cell_eval}\")\n",
    "\n",
    "# Load stopwords for this cell\n",
    "try:\n",
    "    with open(STOPWORDS_PATH_EVAL, 'r', encoding='utf-8') as f:\n",
    "        vi_stopwords_global_cell_eval = set([line.strip() for line in f if line.strip()])\n",
    "    print(f\"Successfully loaded {len(vi_stopwords_global_cell_eval)} Vietnamese stopwords from {STOPWORDS_PATH_EVAL}.\")\n",
    "except FileNotFoundError:\n",
    "    print(f\"Warning: Vietnamese stopwords file not found at {STOPWORDS_PATH_EVAL}. Proceeding without custom stopwords.\")\n",
    "    vi_stopwords_global_cell_eval = set()\n",
    "\n",
    "# Load dataset\n",
    "print(f\"Loading dataset from: {DATASET_PATH_EVAL}\")\n",
    "eval_texts_list = []\n",
    "eval_labels_list = []\n",
    "try:\n",
    "    df_eval_cell_full = pd.read_csv(DATASET_PATH_EVAL)\n",
    "    if 'content' not in df_eval_cell_full.columns or 'label' not in df_eval_cell_full.columns:\n",
    "        raise ValueError(\"Dataset CSV must contain 'content' and 'label' columns.\")\n",
    "    \n",
    "    df_eval_cell_full['label'] = pd.to_numeric(df_eval_cell_full['label'], errors='coerce')\n",
    "    df_eval_cell_full.dropna(subset=['content', 'label'], inplace=True) # Drop rows where content or label is NaN\n",
    "    df_eval_cell_full['label'] = df_eval_cell_full['label'].astype(int) # Convert valid labels to int\n",
    "    \n",
    "    # Determine the split for evaluation to match the training validation set logic\n",
    "    # The training script (finetuneSA.py) splits the full dataset 80/20 after creating a TensorDataset.\n",
    "    # We replicate this split logic here to get the same validation set.\n",
    "    # torch.manual_seed(SEED_EVAL) has already been called earlier in this cell.\n",
    "\n",
    "    num_total_samples = len(df_eval_cell_full)\n",
    "    \n",
    "    if num_total_samples > 0:\n",
    "        # Create a dummy dataset of indices. The split is based on these indices.\n",
    "        all_indices_tensor = torch.arange(num_total_samples)\n",
    "        full_indices_dataset = TensorDataset(all_indices_tensor)\n",
    "\n",
    "        # Calculate split sizes (80% train, 20% validation)\n",
    "        train_size = int(0.8 * num_total_samples)\n",
    "        val_size = num_total_samples - train_size\n",
    "\n",
    "        # Perform the split to get the indices for the validation set\n",
    "        # The first returned dataset from random_split would be the training set indices,\n",
    "        # the second is the validation set indices. We only need the latter.\n",
    "        if train_size + val_size == num_total_samples: # Ensure split sizes sum correctly\n",
    "            _, val_subset_indices_dataset = torch.utils.data.random_split(full_indices_dataset, [train_size, val_size])\n",
    "            \n",
    "            # val_subset_indices_dataset.indices contains the indices from the original full_indices_dataset\n",
    "            # that belong to the validation set. These are the row indices for df_eval_cell_full.\n",
    "            validation_indices = val_subset_indices_dataset.indices\n",
    "            \n",
    "            # Select the 20% validation split from the original DataFrame using these indices\n",
    "            df_eval_cell = df_eval_cell_full.iloc[validation_indices].reset_index(drop=True)\n",
    "            print(f\"Deterministically selected the 20% validation split ({len(df_eval_cell)} samples out of {num_total_samples}) \"\n",
    "                  f\"consistent with training procedure (using SEED: {SEED_EVAL}).\")\n",
    "        else:\n",
    "            # This case should ideally not happen if num_total_samples > 0\n",
    "            print(f\"Warning: Could not perform split correctly for {num_total_samples} samples. Using full dataset for evaluation.\")\n",
    "            df_eval_cell = df_eval_cell_full \n",
    "    else:\n",
    "        print(\"Dataset is empty. No samples to select for evaluation.\")\n",
    "        df_eval_cell = df_eval_cell_full # df_eval_cell will be an empty DataFrame\n",
    "\n",
    "    # The original print statement, now conditional or adjusted\n",
    "    if not df_eval_cell.empty:\n",
    "        print(f\"Using {len(df_eval_cell)} rows for evaluation, corresponding to the validation set.\")\n",
    "    elif num_total_samples > 0 and df_eval_cell.empty : # If split failed to select anything from non-empty\n",
    "        print(f\"Warning: Validation set selection resulted in 0 samples from {num_total_samples} total.\")\n",
    "    # If num_total_samples was 0, the \"Dataset is empty\" message already printed.\n",
    "\n",
    "    eval_texts_list = df_eval_cell['content'].tolist()\n",
    "    eval_labels_list = df_eval_cell['label'].tolist()\n",
    "    print(f\"Loaded {len(eval_texts_list)} samples for evaluation after cleaning and sampling.\")\n",
    "\n",
    "except FileNotFoundError:\n",
    "    print(f\"ERROR: Dataset file not found at {DATASET_PATH_EVAL}. Cannot proceed.\")\n",
    "except ValueError as ve:\n",
    "    print(f\"ERROR: Value error in dataset: {ve}. Cannot proceed.\")\n",
    "except Exception as e:\n",
    "    print(f\"Error loading or processing dataset: {e}. Cannot proceed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Evaluating model: ./fine_tuned_sa_manual_newPreprocess_models/vietnamese-bi-encoder ---\n",
      "Loading tokenizer from: ./fine_tuned_sa_manual_newPreprocess_models/vietnamese-bi-encoder\n",
      "Loading model from: ./fine_tuned_sa_manual_newPreprocess_models/vietnamese-bi-encoder\n",
      "Preprocessing texts for dataloaders...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Preprocessing V2: 100%|██████████| 9523/9523 [00:09<00:00, 1002.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenizing texts...\n",
      "Using validation split for evaluation. Validation dataset size: 1905\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 80/80 [00:04<00:00, 18.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Results for ./fine_tuned_sa_manual_newPreprocess_models/vietnamese-bi-encoder:\n",
      "Validation Accuracy: 0.9144\n",
      "Validation Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Tiêu cực       0.93      0.93      0.93       569\n",
      "  Trung tính       0.70      0.62      0.66       229\n",
      "    Tích cực       0.95      0.97      0.96      1107\n",
      "\n",
      "    accuracy                           0.91      1905\n",
      "   macro avg       0.86      0.84      0.85      1905\n",
      "weighted avg       0.91      0.91      0.91      1905\n",
      "\n",
      "\n",
      "--- Evaluating model: ./fine_tuned_sa_manual_newPreprocess_models/visobert ---\n",
      "Loading tokenizer from: ./fine_tuned_sa_manual_newPreprocess_models/visobert\n",
      "Loading model from: ./fine_tuned_sa_manual_newPreprocess_models/visobert\n",
      "Preprocessing texts for dataloaders...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Preprocessing V2: 100%|██████████| 9523/9523 [00:09<00:00, 997.33it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenizing texts...\n",
      "Using validation split for evaluation. Validation dataset size: 1905\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 80/80 [00:04<00:00, 18.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Results for ./fine_tuned_sa_manual_newPreprocess_models/visobert:\n",
      "Validation Accuracy: 0.9417\n",
      "Validation Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Tiêu cực       0.95      0.97      0.96       569\n",
      "  Trung tính       0.82      0.72      0.77       229\n",
      "    Tích cực       0.96      0.97      0.97      1107\n",
      "\n",
      "    accuracy                           0.94      1905\n",
      "   macro avg       0.91      0.89      0.90      1905\n",
      "weighted avg       0.94      0.94      0.94      1905\n",
      "\n",
      "\n",
      "--- Overall Comparison (based on Validation Accuracy) ---\n",
      "Model: ./fine_tuned_sa_manual_newPreprocess_models/vietnamese-bi-encoder, Accuracy: 0.9144\n",
      "Model: ./fine_tuned_sa_manual_newPreprocess_models/visobert, Accuracy: 0.9417\n",
      "\n",
      "Best performing model: ./fine_tuned_sa_manual_newPreprocess_models/visobert (Accuracy: 0.9417)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "## Evaluating using 20% of the dataset like what we have done in the finetuning code\n",
    "\n",
    "# --- Evaluation Loop ---\n",
    "if eval_texts_list and eval_labels_list:\n",
    "    evaluation_results = {}\n",
    "    for model_id_eval in MODEL_IDENTIFIERS_EVAL:\n",
    "        print(f\"\\n--- Evaluating model: {model_id_eval} ---\")\n",
    "        # model_full_path = os.path.join(OUTPUT_DIR_BASE_EVAL, model_id_eval)\n",
    "\n",
    "        # if not os.path.exists(model_full_path):\n",
    "        #     print(f\"Model path not found: {model_full_path}. Skipping.\")\n",
    "        #     continue\n",
    "\n",
    "        tokenizer_eval, model_eval = load_model_cell_eval(model_id_eval, NUM_LABELS_EVAL)\n",
    "\n",
    "        if model_eval and tokenizer_eval:\n",
    "            # Prepare dataloader using the validation split from the original dataset\n",
    "            val_dataloader_for_eval = prepare_data_for_cell_eval(\n",
    "                eval_texts_list, eval_labels_list, tokenizer_eval, \n",
    "                MAX_SEQ_LENGTH_EVAL, BATCH_SIZE_EVAL, SEED_EVAL\n",
    "            )\n",
    "            \n",
    "            if val_dataloader_for_eval:\n",
    "                accuracy_val, report_val = evaluate_model_cell_eval(model_eval, val_dataloader_for_eval)\n",
    "                evaluation_results[model_id_eval] = {\"accuracy\": accuracy_val, \"report\": report_val}\n",
    "                \n",
    "                print(f\"\\nResults for {model_id_eval}:\")\n",
    "                print(f\"Validation Accuracy: {accuracy_val:.4f}\")\n",
    "                print(\"Validation Classification Report:\")\n",
    "                print(report_val)\n",
    "            else:\n",
    "                print(f\"Failed to create dataloader for {model_id_eval}. Skipping evaluation for this model.\")\n",
    "        else:\n",
    "            print(f\"Failed to load model or tokenizer for {model_id_eval}. Skipping.\")\n",
    "\n",
    "    # --- Comparison ---\n",
    "    print(\"\\n--- Overall Comparison (based on Validation Accuracy) ---\")\n",
    "    if evaluation_results:\n",
    "        for model_id_res, res_data in evaluation_results.items():\n",
    "            print(f\"Model: {model_id_res}, Accuracy: {res_data['accuracy']:.4f}\")\n",
    "        \n",
    "        if evaluation_results: # Ensure not empty before calling max\n",
    "            best_model_name = max(evaluation_results, key=lambda k: evaluation_results[k]['accuracy'])\n",
    "            print(f\"\\nBest performing model: {best_model_name} (Accuracy: {evaluation_results[best_model_name]['accuracy']:.4f})\")\n",
    "    else:\n",
    "        print(\"No models were successfully evaluated, or no results were recorded.\")\n",
    "else:\n",
    "    print(\"Evaluation cannot proceed: Dataset is empty or failed to load.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda:7\n",
      "Successfully loaded 1942 Vietnamese stopwords from vietnamese-stopwords.txt.\n",
      "Loading dataset from: sentiment_analysis_dataset.csv\n",
      "Loaded 47611 samples for evaluation after cleaning.\n",
      "\n",
      "--- Evaluating model: ./fine_tuned_sa_manual_models/vietnamese-bi-encoder ---\n",
      "Loading tokenizer from: ./fine_tuned_sa_manual_models/vietnamese-bi-encoder\n",
      "Loading model from: ./fine_tuned_sa_manual_models/vietnamese-bi-encoder\n",
      "Preprocessing texts for dataloaders...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Preprocessing: 100%|██████████| 47611/47611 [00:00<00:00, 107117.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenizing texts...\n",
      "Using validation split for evaluation. Validation dataset size: 9523\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 397/397 [00:31<00:00, 12.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Results for ./fine_tuned_sa_manual_models/vietnamese-bi-encoder:\n",
      "Validation Accuracy: 0.8756\n",
      "Validation Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Tiêu cực       0.87      0.87      0.87      2831\n",
      "  Trung tính       0.69      0.51      0.59      1103\n",
      "    Tích cực       0.90      0.95      0.93      5589\n",
      "\n",
      "    accuracy                           0.88      9523\n",
      "   macro avg       0.82      0.78      0.79      9523\n",
      "weighted avg       0.87      0.88      0.87      9523\n",
      "\n",
      "\n",
      "--- Evaluating model: ./fine_tuned_sa_manual_models/visobert ---\n",
      "Loading tokenizer from: ./fine_tuned_sa_manual_models/visobert\n",
      "Loading model from: ./fine_tuned_sa_manual_models/visobert\n",
      "Preprocessing texts for dataloaders...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Preprocessing: 100%|██████████| 47611/47611 [00:00<00:00, 85019.04it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenizing texts...\n",
      "Using validation split for evaluation. Validation dataset size: 9523\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 397/397 [00:31<00:00, 12.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Results for ./fine_tuned_sa_manual_models/visobert:\n",
      "Validation Accuracy: 0.9097\n",
      "Validation Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Tiêu cực       0.91      0.90      0.91      2831\n",
      "  Trung tính       0.81      0.67      0.74      1103\n",
      "    Tích cực       0.92      0.96      0.94      5589\n",
      "\n",
      "    accuracy                           0.91      9523\n",
      "   macro avg       0.88      0.84      0.86      9523\n",
      "weighted avg       0.91      0.91      0.91      9523\n",
      "\n",
      "\n",
      "--- Evaluating model: ./fine_tuned_sa_manual_models/phobert-base-v2 ---\n",
      "Loading tokenizer from: ./fine_tuned_sa_manual_models/phobert-base-v2\n",
      "Loading model from: ./fine_tuned_sa_manual_models/phobert-base-v2\n",
      "Preprocessing texts for dataloaders...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Preprocessing: 100%|██████████| 47611/47611 [00:00<00:00, 103529.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenizing texts...\n",
      "Using validation split for evaluation. Validation dataset size: 9523\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 397/397 [00:31<00:00, 12.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Results for ./fine_tuned_sa_manual_models/phobert-base-v2:\n",
      "Validation Accuracy: 0.8620\n",
      "Validation Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Tiêu cực       0.87      0.86      0.86      2831\n",
      "  Trung tính       0.65      0.44      0.52      1103\n",
      "    Tích cực       0.89      0.95      0.92      5589\n",
      "\n",
      "    accuracy                           0.86      9523\n",
      "   macro avg       0.80      0.75      0.77      9523\n",
      "weighted avg       0.85      0.86      0.85      9523\n",
      "\n",
      "\n",
      "--- Evaluating model: ./fine_tuned_sa_manual_models/Multilingual-MiniLM-L12-H384 ---\n",
      "Loading tokenizer from: ./fine_tuned_sa_manual_models/Multilingual-MiniLM-L12-H384\n",
      "Loading model from: ./fine_tuned_sa_manual_models/Multilingual-MiniLM-L12-H384\n",
      "Preprocessing texts for dataloaders...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Preprocessing: 100%|██████████| 47611/47611 [00:00<00:00, 110152.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenizing texts...\n",
      "Using validation split for evaluation. Validation dataset size: 9523\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 397/397 [00:12<00:00, 32.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Results for ./fine_tuned_sa_manual_models/Multilingual-MiniLM-L12-H384:\n",
      "Validation Accuracy: 0.8140\n",
      "Validation Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Tiêu cực       0.79      0.81      0.80      2831\n",
      "  Trung tính       0.50      0.24      0.33      1103\n",
      "    Tích cực       0.85      0.93      0.89      5589\n",
      "\n",
      "    accuracy                           0.81      9523\n",
      "   macro avg       0.71      0.66      0.67      9523\n",
      "weighted avg       0.79      0.81      0.80      9523\n",
      "\n",
      "\n",
      "--- Overall Comparison (based on Validation Accuracy) ---\n",
      "Model: ./fine_tuned_sa_manual_models/vietnamese-bi-encoder, Accuracy: 0.8756\n",
      "Model: ./fine_tuned_sa_manual_models/visobert, Accuracy: 0.9097\n",
      "Model: ./fine_tuned_sa_manual_models/phobert-base-v2, Accuracy: 0.8620\n",
      "Model: ./fine_tuned_sa_manual_models/Multilingual-MiniLM-L12-H384, Accuracy: 0.8140\n",
      "\n",
      "Best performing model: ./fine_tuned_sa_manual_models/visobert (Accuracy: 0.9097)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "## Evaluating using the whole dataset\n",
    "# --- Evaluation Loop ---\n",
    "if eval_texts_list and eval_labels_list:\n",
    "    evaluation_results = {}\n",
    "    for model_id_eval in MODEL_IDENTIFIERS_EVAL:\n",
    "        print(f\"\\n--- Evaluating model: {model_id_eval} ---\")\n",
    "        # model_full_path = os.path.join(OUTPUT_DIR_BASE_EVAL, model_id_eval)\n",
    "\n",
    "        # if not os.path.exists(model_full_path):\n",
    "        #     print(f\"Model path not found: {model_full_path}. Skipping.\")\n",
    "        #     continue\n",
    "\n",
    "        tokenizer_eval, model_eval = load_model_cell_eval(model_id_eval, NUM_LABELS_EVAL)\n",
    "\n",
    "        if model_eval and tokenizer_eval:\n",
    "            # Prepare dataloader using the validation split from the original dataset\n",
    "            val_dataloader_for_eval = prepare_data_for_cell_eval(\n",
    "                eval_texts_list, eval_labels_list, tokenizer_eval, \n",
    "                MAX_SEQ_LENGTH_EVAL, BATCH_SIZE_EVAL, SEED_EVAL\n",
    "            )\n",
    "            \n",
    "            if val_dataloader_for_eval:\n",
    "                accuracy_val, report_val = evaluate_model_cell_eval(model_eval, val_dataloader_for_eval)\n",
    "                evaluation_results[model_id_eval] = {\"accuracy\": accuracy_val, \"report\": report_val}\n",
    "                \n",
    "                print(f\"\\nResults for {model_id_eval}:\")\n",
    "                print(f\"Validation Accuracy: {accuracy_val:.4f}\")\n",
    "                print(\"Validation Classification Report:\")\n",
    "                print(report_val)\n",
    "            else:\n",
    "                print(f\"Failed to create dataloader for {model_id_eval}. Skipping evaluation for this model.\")\n",
    "        else:\n",
    "            print(f\"Failed to load model or tokenizer for {model_id_eval}. Skipping.\")\n",
    "\n",
    "    # --- Comparison ---\n",
    "    print(\"\\n--- Overall Comparison (based on Validation Accuracy) ---\")\n",
    "    if evaluation_results:\n",
    "        for model_id_res, res_data in evaluation_results.items():\n",
    "            print(f\"Model: {model_id_res}, Accuracy: {res_data['accuracy']:.4f}\")\n",
    "        \n",
    "        if evaluation_results: # Ensure not empty before calling max\n",
    "            best_model_name = max(evaluation_results, key=lambda k: evaluation_results[k]['accuracy'])\n",
    "            print(f\"\\nBest performing model: {best_model_name} (Accuracy: {evaluation_results[best_model_name]['accuracy']:.4f})\")\n",
    "    else:\n",
    "        print(\"No models were successfully evaluated, or no results were recorded.\")\n",
    "else:\n",
    "    print(\"Evaluation cannot proceed: Dataset is empty or failed to load.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "--- Evaluating NON-FINETUNED Base Models ---\n",
      "This will evaluate the performance of the base models before any fine-tuning.\n",
      "\n",
      "--- Evaluating base model: vinai/phobert-base-v2 ---\n",
      "Loading tokenizer from: vinai/phobert-base-v2\n",
      "Loading model from: vinai/phobert-base-v2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at vinai/phobert-base-v2 and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocessing texts for dataloaders...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Preprocessing: 100%|██████████| 9523/9523 [00:00<00:00, 109502.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenizing texts...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using validation split for evaluation. Validation dataset size: 1905\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 80/80 [00:03<00:00, 21.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Results for base model vinai/phobert-base-v2:\n",
      "Validation Accuracy: 0.2814\n",
      "Validation Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Tiêu cực       0.24      0.32      0.27       569\n",
      "  Trung tính       0.14      0.42      0.21       229\n",
      "    Tích cực       0.59      0.23      0.34      1107\n",
      "\n",
      "    accuracy                           0.28      1905\n",
      "   macro avg       0.32      0.32      0.27      1905\n",
      "weighted avg       0.43      0.28      0.30      1905\n",
      "\n",
      "\n",
      "--- Evaluating base model: uitnlp/visobert ---\n",
      "Loading tokenizer from: uitnlp/visobert\n",
      "Loading model from: uitnlp/visobert\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of XLMRobertaForSequenceClassification were not initialized from the model checkpoint at uitnlp/visobert and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocessing texts for dataloaders...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Preprocessing: 100%|██████████| 9523/9523 [00:00<00:00, 110373.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenizing texts...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using validation split for evaluation. Validation dataset size: 1905\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 80/80 [00:03<00:00, 21.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Results for base model uitnlp/visobert:\n",
      "Validation Accuracy: 0.3528\n",
      "Validation Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Tiêu cực       0.33      0.07      0.12       569\n",
      "  Trung tính       0.10      0.37      0.15       229\n",
      "    Tích cực       0.61      0.49      0.55      1107\n",
      "\n",
      "    accuracy                           0.35      1905\n",
      "   macro avg       0.34      0.31      0.27      1905\n",
      "weighted avg       0.46      0.35      0.37      1905\n",
      "\n",
      "\n",
      "--- Evaluating base model: bkai-foundation-models/vietnamese-bi-encoder ---\n",
      "Loading tokenizer from: bkai-foundation-models/vietnamese-bi-encoder\n",
      "Loading model from: bkai-foundation-models/vietnamese-bi-encoder\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at bkai-foundation-models/vietnamese-bi-encoder and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocessing texts for dataloaders...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Preprocessing: 100%|██████████| 9523/9523 [00:00<00:00, 116809.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenizing texts...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using validation split for evaluation. Validation dataset size: 1905\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 80/80 [00:03<00:00, 21.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Results for base model bkai-foundation-models/vietnamese-bi-encoder:\n",
      "Validation Accuracy: 0.4047\n",
      "Validation Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Tiêu cực       0.23      0.26      0.25       569\n",
      "  Trung tính       0.14      0.13      0.13       229\n",
      "    Tích cực       0.56      0.53      0.55      1107\n",
      "\n",
      "    accuracy                           0.40      1905\n",
      "   macro avg       0.31      0.31      0.31      1905\n",
      "weighted avg       0.41      0.40      0.41      1905\n",
      "\n",
      "\n",
      "--- Evaluating base model: microsoft/Multilingual-MiniLM-L12-H384 ---\n",
      "Loading tokenizer from: microsoft/Multilingual-MiniLM-L12-H384\n",
      "Loading model from: microsoft/Multilingual-MiniLM-L12-H384\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at microsoft/Multilingual-MiniLM-L12-H384 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocessing texts for dataloaders...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Preprocessing: 100%|██████████| 9523/9523 [00:00<00:00, 115730.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenizing texts...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using validation split for evaluation. Validation dataset size: 1905\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 80/80 [00:01<00:00, 59.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Results for base model microsoft/Multilingual-MiniLM-L12-H384:\n",
      "Validation Accuracy: 0.5811\n",
      "Validation Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Tiêu cực       0.00      0.00      0.00       569\n",
      "  Trung tính       0.00      0.00      0.00       229\n",
      "    Tích cực       0.58      1.00      0.74      1107\n",
      "\n",
      "    accuracy                           0.58      1905\n",
      "   macro avg       0.19      0.33      0.25      1905\n",
      "weighted avg       0.34      0.58      0.43      1905\n",
      "\n",
      "\n",
      "--- Overall Comparison for NON-FINETUNED Base Models (based on Validation Accuracy) ---\n",
      "Base Model: vinai/phobert-base-v2, Accuracy: 0.2814\n",
      "Base Model: uitnlp/visobert, Accuracy: 0.3528\n",
      "Base Model: bkai-foundation-models/vietnamese-bi-encoder, Accuracy: 0.4047\n",
      "Base Model: microsoft/Multilingual-MiniLM-L12-H384, Accuracy: 0.5811\n",
      "\n",
      "Best performing NON-FINETUNED base model: microsoft/Multilingual-MiniLM-L12-H384 (Accuracy: 0.5811)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Define base model Hugging Face identifiers corresponding to the finetuned models\n",
    "# These are the original, non-finetuned versions from Hugging Face.\n",
    "BASE_MODEL_HF_IDENTIFIERS = [\n",
    "    \"vinai/phobert-base-v2\",\n",
    "    \"uitnlp/visobert\",\n",
    "    \"bkai-foundation-models/vietnamese-bi-encoder\",\n",
    "    \"microsoft/Multilingual-MiniLM-L12-H384\"\n",
    "]\n",
    "\n",
    "print(\"\\n\\n--- Evaluating NON-FINETUNED Base Models ---\")\n",
    "print(\"This will evaluate the performance of the base models before any fine-tuning.\")\n",
    "\n",
    "# Ensure the evaluation dataset is available (loaded in a previous cell)\n",
    "if 'eval_texts_list' in globals() and 'eval_labels_list' in globals() and \\\n",
    "   eval_texts_list and eval_labels_list:\n",
    "    \n",
    "    base_model_evaluation_results = {}\n",
    "    for model_hf_id in BASE_MODEL_HF_IDENTIFIERS:\n",
    "        print(f\"\\n--- Evaluating base model: {model_hf_id} ---\")\n",
    "        \n",
    "        # Load the base model directly from Hugging Face.\n",
    "        # load_model_cell_eval is assumed to be defined in a previous cell and\n",
    "        # should handle Hugging Face model identifiers.\n",
    "        # NUM_LABELS_EVAL is also assumed to be defined.\n",
    "        tokenizer_base_eval, model_base_eval = load_model_cell_eval(model_hf_id, NUM_LABELS_EVAL)\n",
    "\n",
    "        if model_base_eval and tokenizer_base_eval:\n",
    "            # Prepare dataloader using the same evaluation data split\n",
    "            # MAX_SEQ_LENGTH_EVAL, BATCH_SIZE_EVAL, SEED_EVAL are assumed to be defined.\n",
    "            val_dataloader_for_base_eval = prepare_data_for_cell_eval(\n",
    "                eval_texts_list, eval_labels_list, tokenizer_base_eval, \n",
    "                MAX_SEQ_LENGTH_EVAL, BATCH_SIZE_EVAL, SEED_EVAL\n",
    "            )\n",
    "            \n",
    "            if val_dataloader_for_base_eval:\n",
    "                # evaluate_model_cell_eval is assumed to be defined.\n",
    "                accuracy_base_val, report_base_val = evaluate_model_cell_eval(model_base_eval, val_dataloader_for_base_eval)\n",
    "                base_model_evaluation_results[model_hf_id] = {\"accuracy\": accuracy_base_val, \"report\": report_base_val}\n",
    "                \n",
    "                print(f\"\\nResults for base model {model_hf_id}:\")\n",
    "                print(f\"Validation Accuracy: {accuracy_base_val:.4f}\")\n",
    "                print(\"Validation Classification Report:\")\n",
    "                print(report_base_val)\n",
    "            else:\n",
    "                print(f\"Failed to create dataloader for base model {model_hf_id}. Skipping evaluation for this model.\")\n",
    "        else:\n",
    "            print(f\"Failed to load model or tokenizer for base model {model_hf_id}. Skipping.\")\n",
    "\n",
    "    # --- Comparison for Base Models ---\n",
    "    print(\"\\n--- Overall Comparison for NON-FINETUNED Base Models (based on Validation Accuracy) ---\")\n",
    "    if base_model_evaluation_results:\n",
    "        for model_id_res, res_data in base_model_evaluation_results.items():\n",
    "            print(f\"Base Model: {model_id_res}, Accuracy: {res_data['accuracy']:.4f}\")\n",
    "        \n",
    "        if base_model_evaluation_results: # Ensure not empty before calling max\n",
    "            best_base_model_name = max(base_model_evaluation_results, key=lambda k: base_model_evaluation_results[k]['accuracy'])\n",
    "            print(f\"\\nBest performing NON-FINETUNED base model: {best_base_model_name} (Accuracy: {base_model_evaluation_results[best_base_model_name]['accuracy']:.4f})\")\n",
    "    else:\n",
    "        print(\"No non-finetuned base models were successfully evaluated, or no results were recorded.\")\n",
    "else:\n",
    "    print(\"Evaluation of non-finetuned base models cannot proceed: Evaluation dataset (eval_texts_list, eval_labels_list) is empty or failed to load from previous cells.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: 'labels' global not found for 3-class. Using default map: {0: 'Negative', 1: 'Neutral', 2: 'Positive'}\n",
      "\n",
      "--- Predicting on Example Vietnamese Texts ---\n",
      "\n",
      "--- Predictions for model: ./fine_tuned_sa_manual_models/visobert ---\n",
      "Loading tokenizer from: ./fine_tuned_sa_manual_models/visobert\n",
      "Loading model from: ./fine_tuned_sa_manual_models/visobert\n",
      "Text: \"Bộ phim này thực sự tuyệt vời! Diễn xuất và cốt truyện đều xuất sắc.\"\n",
      "  Expected: Positive\n",
      "  Predicted: Positive\n",
      "\n",
      "Text: \"Tôi không thích cuốn sách này lắm, nó khá nhàm chán và dễ đoán.\"\n",
      "  Expected: Negative\n",
      "  Predicted: Negative\n",
      "\n",
      "Text: \"Sản phẩm ở mức trung bình, không có gì đặc biệt nhưng cũng không tệ.\"\n",
      "  Expected: Neutral\n",
      "  Predicted: Neutral\n",
      "\n",
      "Text: \"Dịch vụ khách hàng rất tệ, họ không giải quyết được vấn đề của tôi và rất thô lỗ.\"\n",
      "  Expected: Negative\n",
      "  Predicted: Negative\n",
      "\n",
      "Text: \"Đây là một trong những trải nghiệm ẩm thực tốt nhất mà tôi từng có. Mọi thứ đều hoàn hảo!\"\n",
      "  Expected: Positive\n",
      "  Predicted: Positive\n",
      "\n",
      "Text: \"Thời tiết hôm nay cũng bình thường, không nắng không mưa.\"\n",
      "  Expected: Neutral\n",
      "  Predicted: Positive\n",
      "\n",
      "Text: \"Chuyến đi thật kinh khủng, khách sạn bẩn và nhân viên thì thiếu chuyên nghiệp. Tôi sẽ không bao giờ quay lại đó nữa. Thật là một sự lãng phí tiền bạc.\"\n",
      "  Expected: Negative\n",
      "  Predicted: Negative\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 1. Combined example texts and their expected labels\n",
    "# The original texts had comments like \"# Positive\" appended, which were parsed out.\n",
    "# This version stores clean texts directly.\n",
    "example_data_vi = [\n",
    "    {\"text\": \"Bộ phim này thực sự tuyệt vời! Diễn xuất và cốt truyện đều xuất sắc.\", \"expected_label\": \"Positive\"},\n",
    "    {\"text\": \"Tôi không thích cuốn sách này lắm, nó khá nhàm chán và dễ đoán.\", \"expected_label\": \"Negative\"},\n",
    "    {\"text\": \"Sản phẩm ở mức trung bình, không có gì đặc biệt nhưng cũng không tệ.\", \"expected_label\": \"Neutral\"},\n",
    "    {\"text\": \"Dịch vụ khách hàng rất tệ, họ không giải quyết được vấn đề của tôi và rất thô lỗ.\", \"expected_label\": \"Negative\"}, # Corresponds to \"Very Negative\" if mapping to 3 classes\n",
    "    {\"text\": \"Đây là một trong những trải nghiệm ẩm thực tốt nhất mà tôi từng có. Mọi thứ đều hoàn hảo!\", \"expected_label\": \"Positive\"}, # Corresponds to \"Very Positive\" if mapping to 3 classes\n",
    "    {\"text\": \"Thời tiết hôm nay cũng bình thường, không nắng không mưa.\", \"expected_label\": \"Neutral\"},\n",
    "    {\"text\": \"Chuyến đi thật kinh khủng, khách sạn bẩn và nhân viên thì thiếu chuyên nghiệp. Tôi sẽ không bao giờ quay lại đó nữa. Thật là một sự lãng phí tiền bạc.\", \"expected_label\": \"Negative\"}  # Corresponds to \"Strongly negative\" if mapping to 3 classes\n",
    "]\n",
    "\n",
    "# Assumptions from previous cell (as per original comments):\n",
    "# - NUM_LABELS_EVAL, MAX_SEQ_LENGTH_EVAL, load_model_cell_eval are defined.\n",
    "# - 'torch' is imported (e.g., import torch).\n",
    "# - 'labels' list might be defined globally if NUM_LABELS_EVAL == 3, used for human-readable labels.\n",
    "# - device_eval might be defined (though model's device is used here for robustness).\n",
    "\n",
    "# 2. Define a consistent label mapping for predictions\n",
    "# This map will be used to convert predicted class indices to human-readable strings.\n",
    "effective_idx_to_label_map = {}\n",
    "if NUM_LABELS_EVAL == 3:\n",
    "    # Prefer 'labels' global if it's valid and matches NUM_LABELS_EVAL for 3-class mapping\n",
    "    if 'labels' in globals() and isinstance(labels, list) and len(labels) == NUM_LABELS_EVAL:\n",
    "        effective_idx_to_label_map = {i: label for i, label in enumerate(labels)}\n",
    "        print(f\"Using 'labels' global for {NUM_LABELS_EVAL}-class mapping: {effective_idx_to_label_map}\")\n",
    "    else:\n",
    "        # Default 3-class mapping if 'labels' is not suitable or not found\n",
    "        effective_idx_to_label_map = {0: \"Negative\", 1: \"Neutral\", 2: \"Positive\"}\n",
    "        if 'labels' not in globals():\n",
    "            print(f\"Warning: 'labels' global not found for {NUM_LABELS_EVAL}-class. Using default map: {effective_idx_to_label_map}\")\n",
    "        elif not (isinstance(labels, list) and len(labels) == NUM_LABELS_EVAL):\n",
    "             print(f\"Warning: Global 'labels' (value: {labels}) is not a list of {NUM_LABELS_EVAL} items. Using default map: {effective_idx_to_label_map}\")\n",
    "elif NUM_LABELS_EVAL == 5: # Example for 5-class models\n",
    "    effective_idx_to_label_map = {\n",
    "        0: \"Very Negative\", \n",
    "        1: \"Negative\", \n",
    "        2: \"Neutral\", \n",
    "        3: \"Positive\", \n",
    "        4: \"Very Positive\"\n",
    "    }\n",
    "else:\n",
    "    # Fallback for other numbers of labels\n",
    "    effective_idx_to_label_map = {i: f\"Label_{i}\" for i in range(NUM_LABELS_EVAL)}\n",
    "    print(f\"Warning: Using generic label map for {NUM_LABELS_EVAL} classes: {effective_idx_to_label_map}. Predictions might not be human-readable.\")\n",
    "\n",
    "print(\"\\n--- Predicting on Example Vietnamese Texts ---\")\n",
    "\n",
    "# Models to use for this example prediction section.\n",
    "# This list is defined within the selection in the original code.\n",
    "model_ids_to_evaluate = [\"./fine_tuned_sa_manual_models/visobert\"] \n",
    "\n",
    "if not model_ids_to_evaluate:\n",
    "    print(\"No models specified in 'model_ids_to_evaluate' for example predictions. Skipping.\")\n",
    "else:\n",
    "    for model_id_pred in model_ids_to_evaluate:\n",
    "        print(f\"\\n--- Predictions for model: {model_id_pred} ---\")\n",
    "        \n",
    "        # Load tokenizer and model. load_model_cell_eval is expected to:\n",
    "        # - Place the model on the correct device (e.g., device_eval).\n",
    "        # - Set the model to evaluation mode (model.eval()).\n",
    "        tokenizer_pred, model_pred = load_model_cell_eval(model_id_pred, NUM_LABELS_EVAL)\n",
    "        \n",
    "        if model_pred and tokenizer_pred:\n",
    "            # Determine the device the model is currently on.\n",
    "            current_device = next(model_pred.parameters()).device\n",
    "\n",
    "            for example_item in example_data_vi:\n",
    "                text_content = example_item[\"text\"]\n",
    "                current_ground_truth_label = example_item[\"expected_label\"]\n",
    "                \n",
    "                # Tokenize the text\n",
    "                inputs = tokenizer_pred(\n",
    "                    text_content, \n",
    "                    return_tensors=\"pt\", \n",
    "                    padding=True, \n",
    "                    truncation=True, \n",
    "                    max_length=MAX_SEQ_LENGTH_EVAL # Assumed from previous cell\n",
    "                )\n",
    "                \n",
    "                # Move inputs to the same device as the model\n",
    "                inputs = {k: v.to(current_device) for k, v in inputs.items()}\n",
    "                \n",
    "                # Make prediction\n",
    "                with torch.no_grad():\n",
    "                    outputs = model_pred(**inputs)\n",
    "                \n",
    "                logits = outputs.logits\n",
    "                predicted_class_idx = torch.argmax(logits, dim=1).item()\n",
    "                \n",
    "                # Map predicted index to label string using the consolidated map\n",
    "                predicted_label = effective_idx_to_label_map.get(predicted_class_idx, f\"Unknown_Index_{predicted_class_idx}\")\n",
    "                \n",
    "                print(f\"Text: \\\"{text_content}\\\"\")\n",
    "                print(f\"  Expected: {current_ground_truth_label}\")\n",
    "                print(f\"  Predicted: {predicted_label}\\n\")\n",
    "        else:\n",
    "            print(f\"Failed to load model or tokenizer for {model_id_pred}. Skipping predictions for this model.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully loaded 1942 Vietnamese stopwords.\n",
      "Using device: cuda:1\n"
     ]
    }
   ],
   "source": [
    "#For testing with single sample\n",
    "\n",
    "try:\n",
    "    with open('/data/elo/khanglg/FreeTxt-Flask/vietnamese-stopwords.txt', 'r', encoding='utf-8') as f:\n",
    "        vi_stopwords = [line.strip() for line in f if line.strip()]\n",
    "    print(f\"Successfully loaded {len(vi_stopwords)} Vietnamese stopwords.\")\n",
    "except FileNotFoundError:\n",
    "    print(\"Vietnamese stopwords file not found. Please check the path.\")\n",
    "    vi_stopwords = []\n",
    "\n",
    "# Define punctuation\n",
    "PUNCS = '''!→()-[]{};:'\"\\,<>?@#$%^&*_~'''\n",
    "\n",
    "# Cell 3: Device Configuration\n",
    "device = torch.device(\"cuda:1\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "def preprocess_text(text, language='vi'):\n",
    "    \"\"\"\n",
    "    Preprocesses text for sentiment analysis:\n",
    "    - Converts input to string to handle potential NaNs or other types\n",
    "    - Removes URLs, mentions, hashtags\n",
    "    - Removes punctuation\n",
    "    - Converts to lowercase\n",
    "    - Removes stopwords\n",
    "    \"\"\"\n",
    "    text = str(text) # Convert text to string to prevent TypeError\n",
    "    text = re.sub(r\"http\\\\S+|@\\\\S+|#\\\\S+\", \"\", text)\n",
    "    text = re.sub(f\"[{re.escape(''.join(PUNCS))}]\", \"\", text.lower())\n",
    "    text = \" \".join(word for word in text.split() if word not in vi_stopwords)\n",
    "    return text\n",
    "\n",
    "def predict_sentiment(text, tokenizer, model, preprocess=True):\n",
    "    \"\"\"\n",
    "    Predicts the sentiment of a single text.\n",
    "    Returns the predicted class and confidence.\n",
    "    \"\"\"\n",
    "    if preprocess:\n",
    "        text = preprocess_text(text)\n",
    "    \n",
    "    encoding = tokenizer(\n",
    "        text,\n",
    "        add_special_tokens=True,\n",
    "        max_length=128,\n",
    "        padding='max_length',\n",
    "        truncation=True,\n",
    "        return_tensors='pt'\n",
    "    )\n",
    "    \n",
    "    input_ids = encoding['input_ids'].to('cuda')\n",
    "    attention_mask = encoding['attention_mask'].to('cuda')\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        if isinstance(model, torch.nn.Module) and not hasattr(model, 'config'):\n",
    "            logits = model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        else:\n",
    "            outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "            logits = outputs.logits\n",
    "    \n",
    "    probabilities = torch.nn.functional.softmax(logits, dim=1).cpu().numpy()[0]\n",
    "    predicted_class = np.argmax(probabilities)\n",
    "    confidence = probabilities[predicted_class]\n",
    "    \n",
    "    # Map class to sentiment\n",
    "    sentiment_map = {0: 'Tiêu cực', 1: 'Trung tính', 2: 'Tích cực'}\n",
    "    predicted_sentiment = sentiment_map.get(predicted_class, 'Unknown')\n",
    "    \n",
    "    return predicted_sentiment, confidence, probabilities\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading tokenizer from: ./fine_tuned_sa_manual_models/visobert\n",
      "Loading model from: ./fine_tuned_sa_manual_models/visobert\n"
     ]
    }
   ],
   "source": [
    "test_tokenizer,test_model = load_model_cell_eval(\"./fine_tuned_sa_manual_models/visobert\",3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample text: 'Đồ ăn như con cặc vậy á đéo tin được!'\n",
      "VISOBERT prediction: Tiêu cực (confidence: 0.9943)\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "sample_text = \"Đồ ăn như con cặc vậy á đéo tin được!\"\n",
    "\n",
    "bkai_sentiment, bkai_conf, bkai_probs = predict_sentiment(sample_text, test_tokenizer, test_model)\n",
    "# pho_sentiment, pho_conf, pho_probs = predict_sentiment(sample_text, pho_tokenizer, pho_model)\n",
    "\n",
    "print(f\"Sample text: '{sample_text}'\")\n",
    "print(f\"VISOBERT prediction: {bkai_sentiment} (confidence: {bkai_conf:.4f})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading tokenizer from: shenkha/FreeTxT-VisoBERT\n",
      "Loading model from: shenkha/FreeTxT-VisoBERT\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "XLMRobertaForSequenceClassification(\n",
       "  (roberta): XLMRobertaModel(\n",
       "    (embeddings): XLMRobertaEmbeddings(\n",
       "      (word_embeddings): Embedding(15004, 768, padding_idx=1)\n",
       "      (position_embeddings): Embedding(514, 768, padding_idx=1)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): XLMRobertaEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-11): 12 x XLMRobertaLayer(\n",
       "          (attention): XLMRobertaAttention(\n",
       "            (self): XLMRobertaSdpaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): XLMRobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): XLMRobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): XLMRobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (classifier): XLMRobertaClassificationHead(\n",
       "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "    (out_proj): Linear(in_features=768, out_features=3, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer,model = load_model_cell_eval(\"shenkha/FreeTxT-VisoBERT\",3)\n",
    "model.to('cuda:1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample text: 'Đồ ăn như con cặc vậy á đéo tin được!'\n",
      "VISOBERT prediction: Tiêu cực (confidence: 0.9670)\n"
     ]
    }
   ],
   "source": [
    "sample_text = \"Đồ ăn như con cặc vậy á đéo tin được!\"\n",
    "\n",
    "sentiment, conf, probs = predict_sentiment(sample_text, tokenizer, model)\n",
    "\n",
    "\n",
    "print(f\"Sample text: '{sample_text}'\")\n",
    "print(f\"VISOBERT prediction: {sentiment} (confidence: {conf:.4f})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "vifree-txt-3.10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
